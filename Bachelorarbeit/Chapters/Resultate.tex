\section{Resultate}
In der nachfolgenden Analyse liegt der Fokus auf der Evaluierung der implementierten Varianten des Shor-Algorithmus hinsichtlich ihres Ressourcenverbrauchs und 
der Laufzeitkomplexität. 
Angesichts der signifikanten Auswirkungen des Algorithmus für die Integrität des kryptographischen Systems des RSA-Verfahrens  
orientieren sich die zugrunde gelegten Bewertungskriterien an den Richtlinien für Post-Quantenkryptographie des \textit{National Institute of Standards and Technology}(NIST). 
Die erzielten Resultate ermöglichen eine Einordnung in die Größenordnung der erforderlichen Laufzeit und 
erlauben einen direkten Vergleich mit den Ergebnissen anderer Arbeiten.

\subsection*{Laufzeit}
In der Publikation "'Submission Requirements and Evaluation Criteria for the Post-Quantum Cryptography Standardization Process"`~\cite{NISTPQC} des \textit{National Institute of Standards and Technology}
werden drei Sicherheitsstufen definiert, die sich auf die Laufzeitanforderungen von Quantencomputern in Bezug auf kryptographische Angriffe beziehen.

Als Metrik für die Laufzeitevaluation wird der Parameter \textit{Maxdepth} eingeführt, 
welcher die Anzahl der Quantengatter für die längste serielle Ausführung eines Quantenalgorithmus erfasst.
Die Auswahl dieser Metrik wird in der Publikation damit begründet, dass lange serielle Berechnungen Herausforderungen mit sich bringen.

Die schwächste der drei Sicherheitsstufe beginnt bei einer \textit{Maxdepth} von \(2^{40}\) Quantengattern. 
Dieser Wert dient als approximative Messgröße für die Anzahl an seriell ausgeführten Quantengattern, 
die nach aktueller Prognose von Quantencomputern innerhalb eines Jahres realisiert werden können.

Die zweite Sicherheitsstufe setzt eine \textit{Maxdepth} von \(2^{64}\) Quantengattern an.
Dieser Wert stellt die approximative Anzahl an seriell ausgeführten Quantengattern dar, 
die nach der Prognose innerhalb eines Jahrzehnts durchgeführt werden können.

Die stärkste Sicherheitsstufe ist bei einer \textit{Maxdepth} von \(2^{96}\) Quantengattern festgelegt. 
Selbst unter idealen Bedingungen, 
bei denen Qubits auf atomarer Skala arbeiten und die Übertragungsgeschwindigkeit der Lichtgeschwindigkeit entspricht, 
würde diese Anzahl an Quantengattern ein Jahrtausend an Berechnungszeit erfordern.


\subsection*{Ressourcenbedarf}
Als Metriken für den Ressourcenverbrauch werden die benötigte Anzahl an Qubits sowie die Gesamtanzahl an Quantengattern herangezogen. 
Die Anzahl der Qubits stellt eine notwendige Voraussetzung dar, 
die ein Quantencomputer erfüllen muss, da andernfalls die Ausführung des Quantenalgorithmus nicht möglich ist. 
Die Gesamtanzahl an Quantengattern dient als eine Kennzahl, 
die potenzielle Rückschlüsse auf die Fehlerrate durch Dekohärenz zulässt. 
Darüber hinaus finden sowohl die Anzahl an Qubits als auch die Gesamtanzahl an Quantengattern häufig Anwendung als Kennzahl in der wissenschaftlichen Literatur. 
Diese beiden Metriken ermöglichen somit einen Vergleich mit den Ergebnissen anderer Arbeiten.

In der Analyse wurden ausschließlich elementare Quantengatter wie Hadamard-, Phasen- und X-Gatter in die Betrachtung einbezogen. 
Die in Sektion~\ref{sec:Implementierung} eingeführten, spezialisierten Gatter wurden nicht direkt gezählt, 
stattdessen wurden die darin enthaltenen Basisgatter gezählt. 
Diese Vorgehen ergibt sich aus der Tatsache, dass ein Quantencomputer effektiv die Basisgatter eines Quantenschaltkreises ausführt. 
Übergeordnete, spezialisierte Gatter werden demzufolge in ihre elementaren Komponenten zerlegt. 
Eine Zählung der spezialisierten Gatter wäre somit nicht repräsentativ für die tatsächliche Ressourcennutzung.

Für die Zählung der Anzahl der Gatter sowie der \textit{Maxdepth} des Quantenschaltkreises wurden spezifische Funktionen der Qiskit-Bibliothek genutzt. 
Diese Funktionen erlauben die Bestimmung der Anzahl an Gatter und der \textit{Maxdepth} in einem Quantenschaltkreis.
Dabei ist zu beachten, dass diese Funktionen keine Unterscheidung zwischen elementaren und spezialisierten Gattern treffen.
Daher konnte die Funktionen nicht direkt zur Analyse des vorliegenden Quantenschaltkreis verwendet werden. 
Als Lösungsansatz wurde der Code zur Zählung modifiziert, um sicherzustellen, dass der Quantenschaltkreis ausschließlich aus Basisgattern besteht.

\subsection*{Analyse}
Die Analyse beinhaltet eine Untersuchung von vier Varianten des Shor-Algorithmus, 
die jeweils unterschiedliche Kombinationen der in Sektion~\ref{Optimierung} erörterten Optimierungsstrategien implementieren.
Die vier Varianten werden nach den implementierten Optimierungsstrategien in die Kategorien \textit{Reguläre}, 
\textit{Approximative}, \textit{Iterative} und \textit{Approximative-Iterative} eingeteilt.
In den Kategorien unterscheidet sich insbesondere die Nutzung der Quantum-Phase-Estimation und der Quanten-Fourier-Transformation. 
Während die \textit{Reguläre} Variante auf die \(4n+2\) Qubit Version der Quantum-Phase-Estimation mit der exakten Quanten-Fourier-Transformation setzt, 
nutzt die \textit{Approximative} Variante ebenfalls die \(4n+2\) Qubit Variante, 
verwendet jedoch die approximative Quanten-Fourier-Transformation mit einem Approximationsfaktor von \(m = \lceil\text{ld}(n)+2\rceil\).

Die \textit{Iterative} Variante bedient sich der iterativen Quantum-Phase-Estimation mit \(2n+3\) Qubits und 
verwendet die exakten Quanten-Fourier-Transformation, dementsprechend in iterativer Anwendung.
Die \textit{Approximative-Iterative} Variante verwendet ebenfalls die iterative Quantum-Phase-Estimation mit \(2n+3\) Qubits, 
aber ergänzt die iterativ angewendete Quanten-Fourier-Transformation um einen Approximationsfaktor von \\\(m = \lceil\text{ld}(n)+2\rceil\).

Die Analyse bezieht sich auf die Schlüssellängen des RSA-Kryptosystems von 1024-Bit, 2048-Bit, 3072-Bit und 4096-Bit. 
Nach aktuellem Stand empfiehlt das BSI für das RSA-Verfahren keine Schlüssellänge unter 3000-Bit~\cite{BSI2023}. 
Nichtsdestotrotz sind heutzutage noch immer Varianten des RSA-Kryptosystems in Einsatz, welche kürzere Schlüssel verwenden, 
weshalb diese ebenfalls berücksichtigt werden.

\vspace{1em}

\begin{table}[H] \label{Varainten_Analyse}
    \centering
    \caption{Vergleich der vier Varianten des Shor-Algorithmus für verschiedene Schlüssellängen}
    \begin{tabular}{|l|l|l|l|l|}
        \hline
        \textbf{Variante} & \textbf{Schlüssellänge} & \textbf{Qubits} & \textbf{Gatteranzahl} & \textbf{Maxdepth} \\ \hline
        Reguläre & 1024-Bit & 4098 & \(2^{43}\) & \(2^{35}\) \\ \hline
        Reguläre & 2048-Bit & 8194 & \(2^{47}\) & \(2^{38}\) \\ \hline
        Reguläre & 3072-Bit & 12290 & \(2^{49}\) & \(2^{40}\) \\ \hline
        Reguläre & 4096-Bit & 16386 & \(2^{51}\) & \(2^{41}\) \\ \hline
        Approximative & 1024-Bit & 4098 & \(2^{38}\) & \(2^{35}\) \\ \hline
        Approximative & 2048-Bit & 8194 & \(2^{41}\) & \(2^{38}\) \\ \hline
        Approximative & 3072-Bit & 12290 & \(2^{43}\) & \(2^{40}\) \\ \hline
        Approximative & 4096-Bit & 16386 & \(2^{44}\) & \(2^{41}\) \\ \hline
        Iterative & 1024-Bit & 2051 & \(2^{43}\) & \(2^{35}\) \\ \hline
        Iterative & 2048-Bit & 4099 & \(2^{47}\) & \(2^{38}\) \\ \hline
        Iterative & 3072-Bit & 6147 & \(2^{49}\) & \(2^{40}\) \\ \hline
        Iterative & 4096-Bit & 8195 & \(2^{51}\) & \(2^{41}\) \\ \hline
        Approximative-Iterative & 1024-Bit & 2051 & \(2^{38}\) & \(2^{35}\) \\ \hline
        Approximative-Iterative & 2048-Bit & 4099 & \(2^{41}\) & \(2^{38}\) \\ \hline
        Approximative-Iterative & 3072-Bit & 6147 & \(2^{43}\) & \(2^{40}\) \\ \hline
        Approximative-Iterative & 4096-Bit & 8195 & \(2^{44}\) & \(2^{41}\) \\ \hline
    \end{tabular}
    \end{table}
    
Anhand der Tabelle~\ref{Varainten_Analyse} fällt auf,
dass die unterschiedlichen Varianten keinen Unterschiede in Bezug auf die \textit{Maxdepth} haben.
Stattdessen ist die Schlüssellänge der einzige Faktor, 
der die \textit{Maxdepth} beeinflusst.

Hingegen ermöglicht der Einsatz eines approximativen und iterativen Ansatzes deutliche Einsparungen im Hinblick auf den Ressourcenbedarf. 
Im Vergleich zu einer Schlüssellänge von 4096-Bit ermöglicht die Verwendung der approximativen Quanten-Fourier-Transformation im Vergleich zur exakten Variante eine Reduzierung der Gesamtanzahl an Gattern um etwa den Faktor 100.
Wie in Sektion~\ref{sec:ApproxQFT} erwähnt, ist der Genauigkeitsverlust durch die approximative Variante für große \(N\) vernachlässigbar. 
Des Weiteren, schneidet die approximative Variante in Anwesenheit von Dekohärenz aufgrund der geringeren Anzahl an Gattern besser ab~\cite{Barenco_1996}. 
Diese Aspekte sprechen dafür, den approximativen Ansatz grundsätzlich Vorzuziehen.

\subsection*{Vergleich}
In Abschnitt~\ref{sec:QuantumAdder} wurde erläutert, 
dass die Verwendung klassischer Volladdierer in einem Quantenschaltkreis mehr Ressourcen erfordert als die Nutzung der Quantum-Addition. 
Da der Baustein zur Addition in Shors Algorithmus häufig vorkommt, 
hat dies dementsprechend einen erheblichen Einfluss auf den Gesamtressourcenbedarf.

Um ein Abwägung beider Methoden durchzuführen, 
werden die Ergebnisse der Analyse mit dem berechneten Ressourcenbedarf aus der Publikation "'Estimation of Shor’s Circuit for 2048-bit Integers
based on Quantum Simulator"`~\cite{cryptoeprint:2023/092} verglichen. 
Diese Publikation untersucht den Ressourcenbedarf für einen ähnlichen Ansatz zur Implementierung des Shor-Algorithmus.
Der entscheidende Unterschied besteht darin, 
dass der in dieser Publikation verwendete Quantenschaltkreis klassische Volladdierer nach der Anleitung von 
\textit{Vedral}, \textit{Barenco} und \textit{Ekert}\cite{Vedral_1996} verwendet.

In Tabelle~\ref{Volladdierer_Analyse} sind die Ergebnisse der Publikation dargestellt:

\begin{table}[H] \label{Volladdierer_Analyse}
    \centering
    \caption{Vergleich Shor-Algorithmus mit Volladdierer~\cite{cryptoeprint:2023/092}}
    \begin{tabular}{|l|l|l|l|l|}
        \hline
        \textbf{Variante} & \textbf{Schlüssellänge} & \textbf{Qubits} & \textbf{Gatteranzahl} & \textbf{Maxdepth} \\ \hline
        Volladdierer & 1024-Bit & 5121 & \(2^{38}\) & \(2^{38}\) \\ \hline
        Volladdierer & 2048-Bit & 10241 & \(2^{41}\) & \(2^{41}\) \\ \hline
    \end{tabular}
\end{table}
In der Publikation werden die Ressourcen nur für Schlüssellängen von jeweils \(1024\) und \(2048\) Bit untersucht. 
Nichtsdestotrotz lässt sich im direkten Vergleich feststellen, 
dass die Verwendung der Quanten-Addition in allen Fällen zu einer geringeren \textit{Maxdepth} führt. 
Darüber hinaus wird der zusätzliche Bedarf an Qubits bei Verwendung von Volladdierern offensichtlich. 
Lediglich im Gesamtbedarf an Quantengattern schneidet die Variante mit Volladdierern besser ab als diejenigen, die die exakte Quanten-Fourier-Transformation nutzen. 
Andererseits weist der approximative Ansatz einen äquivalenten Gesamtbedarf an Quantengattern auf.

\subsection*{Effekt der Nachberechnung}

Bezüglich der \textit{Maxdepth} erfüllt eine Schlüssellänge von mindestens 3072 Bit die Kriterien der geringsten Sicherheitsstufe. 
Es ist jedoch zu beachten, dass diese \textit{Maxdepth} nur für einen einzelnen Durchlauf des Quantenalgorithmus gilt. 
Wenn mehrere Durchläufe benötigt werden, steigt dementsprechend auch die \textit{Maxdepth} der gesamten Berechnung.

Wie in Sektion~\ref{Funktionsweise:klassisch} erklärt, kann es ohne klassische Nachberechnungen bis zu \(2\text{ld}(N)\) Messungen erfordern, 
bis ein Messergebnis die ungekürzte Periode enthält. 
Im Bezug auf eine Schlüssellänge von 3072 Bit würde das im Worst-Case-Szenario \(2\text{ld}(2^{3072})\) erfordern, 
also in etwa \(2^{13}\) Durchläufe des Quantenalgorithmus.
Dies ergibt eine gesamte \textit{Maxdepth} aller Durchläufe von \(2^{40} \cdot 2^{13}\), insgesamt also \(2^{53}\).
Unter Berücksichtigung der erforderlichen Laufzeiten wird die Sinnhaftigkeit intensiver Nachberechnungen mit klassischen Methoden verdeutlicht.

Um einen Vergleich zwischen den benötigten Durchläufen mit Nachberechnung und den Durchläufen ohne Nachberechnung zu ermöglichen, 
wurden die Erfolgsraten beider Methoden erhoben.

Dazu wurden beide Methoden verwendet, um die Zahl \(N=391\) jeweils 200-mal zu faktorisieren.
Die Statistik beinhaltet die benötigten Durchläufe, die pro Faktorisierung notwendig waren.

Die Berechnung des Quantenalgorithmus wurde unter Verwendung der Qiskit-Simulation durchgeführt. 
Bei jedem Durchlauf wurde ein zufälliges \(a\) gewählt.
Um die Statistik nicht zu verfälschen, wurden Durchläufe, die ein \(a\) verwendeten, 
welches ein Faktor von \(N\) war, nicht gezählt.

Beide Methoden verwendeten die Approximative-Iterative Variante des Quantenalgorithmus mit einem standardmäßigen \(k=2n\) und \(m=\lceil\text{ld}(n)+2\rceil\),
wie es auch in der Implementierung in Sektion~\ref{sec:Implementierung} standardmäßig verwendet wurde. 
Für die Nachberechnung wurde das gleiche Verfahren wie in Sektion~\ref{sec:Faktorisierungsalgorithmus} beschrieben angewendet. 
Die Anzahl der zu überprüfenden Nachbarn und Vielfachen in der klassischen Nachberechnung betrug ebenfalls den standardmäßigen Wert von \(2^{\text{ld}(\text{ld}(N))}\).

Für die Auswertung wurden keine größeren Zahlen zur Faktorisierung gewählt, 
da die Simulation bereits für diese Größenordnung bei 200 Durchläufen mehrere Tage in Anspruch nahm.

%{1: 168, 4: 1, 2: 31, 3: 4}
\subsection*{Kritik}

Anhand der in Tabelle~\ref{Varainten_Analyse} aufgeführten \textit{Maxdepth}-Werte lässt sich erkennen, 
dass selbst unter optimalen Bedingungen, bei denen ein einzelner Durchlauf zur Faktorisierung führt, 
der implementierte Quantenalgorithmus für Schlüssellängen ab 3072 Bit eine Laufzeit erfordert, 
die den niedrigsten Sicherheitsanforderungen gemäß den NIST-Kriterien entspricht. 
Dies verdeutlicht, dass die verwendete Implementierung des Quantenschaltkreises in dieser Arbeit keine effiziente Methode darstellt, 
um ein RSA-Verfahren mit den derzeit empfohlenen Schlüssellängen zu kompromittieren.

Stattdessen wird für die effiziente Faktorisierung ein Quantenschaltkreis benötigt, 
der für Schlüssellängen mit mehr als 3072 Bit eine geringere \textit{Maxdepth} als \(2^{40} \) aufweist.

In Abschnitt~\ref{Funktionsweise:klassisch} wurde darauf hingewiesen, 
dass im Grunde genommen ein Wert \(k\) mit \(k > 2\text{ld}(p)\) ausreichend Genauigkeit gewährt.
Ein möglicher Ansatz zur Reduzierung der \textit{Maxdepth} des hier verwendeten Quantenschaltkreises besteht darin, 
auf eine geringere Größenordnung der Periode zu spekulieren, 
um einen Quantenschaltkreis mit einer kleineren \textit{Maxdepth} zu erreichen~\cite{Shor_1997}. 
Zum Beispiel würde ein \(p\) in der Größenordnung von \(2^{1500}\) mit einem entsprechenden \(k = 2\text{ld}(2^{1500})\) dazu führen, 
dass die \textit{Maxdepth} des Quantenschaltkreises von \(2^{40}\) auf \(2^{37}\) reduziert wird. 
Es ist jedoch wichtig zu betonen, dass die Erfolgswahrscheinlichkeit dieses Ansatzes kritisch zu betrachten ist. 
In einem Szenario mit einem Gesamtraum von \(2^{3072}\) ist es äußerst unwahrscheinlich, 
dass eine Periode mit einem kleineren Wert als \(2^{1500}\) vorkommt.
Konkret ist der gesamte Raum um den Faktor \(\frac{2^{3072}}{2^{1500}} = 2^{1572}\) größer als die vermutete Größe der Periode. 
Daher ist die Wahrscheinlichkeit, dass die Periode größer als \(2^{1500}\) ist, 
um einen ähnlichen Faktor höher als die Wahrscheinlichkeit, 
dass sie kleiner als \(2^{1500}\) ist.

\subsection*{Schlussfolgerung}

Daraus lässt sich ableiten, 
dass eine äußerst ressourceneffiziente Implementierung in Bezug auf die Anzahl der benötigten Qubits 
für die Faktorisierung sehr großer \(N\) zu zeitaufwändigen Berechnungen führt. 
Somit ergibt sich die Schlussfolgerung, 
dass der Fokus bei der Konstruktion des Quantenschaltkreises nicht auf einem möglichst sparsamen Qubit-Bedarf liegen sollte.

Es ist denkbar, dass durch die Verwendung zusätzlicher Qubits ein Quantenschaltkreis mit einer geringeren \textit{Maxdepth} konstruiert werden kann. 
Das mögliche Vorgehen bei der Konstruktion eines solchen Quantenschaltkreises könnte sich auf die Parallelisierung der Berechnung konzentrieren. 
Eine weitere potenzielle Einsparmöglichkeit besteht bei dem Baustein der modularen Addition aus Sektion~\ref{sub:modulareAddition}. 
Indem auf die Quantengatter verzichtet wird, welche das Bedingungs-Qubit zurücksetzen, 
kann die \textit{Maxdepth} dieses Bausteines um mehr als die Hälfte eingespart werden. 
Statt einer Zurücksetzung könnte stattdessen ein neues Qubit verwendet werden. Konkrete Ansätze erfordern jedoch eine ausführliche Untersuchung.


